{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93b6b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import av\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4801a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "test_dir = f'{data_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "701a6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_df = pd.read_csv(f'{data_dir}/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e81c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = {f\"{test_dir}/{k[0]}\": k[1] for k in test_label_df.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9096417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique label: 226\n"
     ]
    }
   ],
   "source": [
    "total_label = pd.read_csv(f'{data_dir}/ClassId.csv')\n",
    "n_classes = len(total_label['ClassId'].unique())\n",
    "print(\"total unique label:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19280d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_label = {k[0]: k[2] for k in total_label.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97a5637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sister', 1: 'hurry', 2: 'hungry', 3: 'enjoy_your_meal', 4: 'brother', 5: 'tree', 6: 'heavy', 7: 'cry', 8: 'family', 9: 'wise', 10: 'unwise', 11: 'kin', 12: 'shopping', 13: 'key', 14: 'mother', 15: 'friend', 16: 'ataturk', 17: 'shoe', 18: 'mirror', 19: 'same', 20: 'father', 21: 'garden', 22: 'look', 23: 'honey', 24: 'glass', 25: 'flag', 26: 'feast', 27: 'baby', 28: 'single', 29: 'wait', 30: 'I', 31: 'petrol', 32: 'together', 33: 'inform', 34: 'we', 35: 'work', 36: 'wednesday', 37: 'fork', 38: 'tea', 39: 'teapot', 40: 'hammer', 41: 'ugly', 42: 'child', 43: 'soup', 44: 'friday', 45: 'saturday', 46: 'wallet', 47: 'minute', 48: 'grandfather', 49: 'change', 50: 'topple', 51: 'government', 52: 'doctor', 53: 'full', 54: 'wedding', 55: 'yesterday', 56: 'enemy', 57: 'wall', 58: 'pharmacy', 59: 'glove', 60: 'labor', 61: 'retired', 62: 'male', 63: 'meal', 64: 'house', 65: 'yes', 66: 'married', 67: 'memorize', 68: 'elephant', 69: 'photograph', 70: 'football', 71: 'past', 72: 'get_well', 73: 'bring', 74: 'lake', 75: 'shirt', 76: 'see', 77: 'show', 78: 'laugh', 79: 'lightweight', 80: 'right', 81: 'carpet', 82: 'ill', 83: 'hospital', 84: 'fault', 85: 'towel', 86: 'no', 87: 'congratulations', 88: 'animal', 89: 'gift', 90: 'halal', 91: 'always', 92: 'never', 93: 'goodbye', 94: 'drink', 95: 'needle', 96: 'medicine', 97: 'not_interested', 98: 'light', 99: 'push', 100: 'good', 101: 'escape', 102: 'breakfast', 103: 'pencil', 104: 'radiator', 105: 'door', 106: 'sibling', 107: 'crossroads', 108: 'accident', 109: 'belt', 110: 'if_only', 111: 'who', 112: 'identity', 113: 'rent', 114: 'book', 115: 'mince', 116: 'female', 117: 'smell', 118: 'cologne', 119: 'coal', 120: 'dog', 121: 'bridge', 122: 'bad', 123: 'lap', 124: 'stain', 125: 'salary', 126: 'scissors', 127: 'tongs', 128: 'god_preserve', 129: 'angel', 130: 'be_pleased', 131: 'napkin', 132: 'stairs', 133: 'guest', 134: 'manager', 135: 'tap', 136: 'how', 137: 'why', 138: 'where', 139: 'grandmother', 140: 'oven', 141: 'room', 142: 'wood', 143: 'teacher', 144: 'school', 145: 'olympiad', 146: 'nope', 147: 'allright', 148: 'they', 149: 'forest', 150: 'fasting', 151: 'apologize', 152: 'cotton', 153: 'trousers', 154: 'money', 155: 'pastrami', 156: 'potato', 157: 'sunday', 158: 'monday', 159: 'window', 160: 'thursday', 161: 'picnic', 162: 'police', 163: 'psychology', 164: 'request', 165: 'hour', 166: 'soap', 167: 'sauce', 168: 'tuesday', 169: 'champion', 170: 'hat', 171: 'war', 172: 'sugar', 173: 'hi', 174: 'umbrella', 175: 'you', 176: 'bill', 177: 'free', 178: 'voice', 179: 'love', 180: 'evil', 181: 'border', 182: 'you', 183: 'say', 184: 'promise', 185: 'milk', 186: 'okay', 187: 'comb', 188: 'date', 189: 'holiday', 190: 'sweet', 191: 'ceiling', 192: 'danger', 193: 'telephone', 194: 'scales', 195: 'tailor', 196: 'thanks', 197: 'screwdriver', 198: 'turkey', 199: 'orange', 200: 'toilet', 201: 'flour', 202: 'far', 203: 'sad', 204: 'existing', 205: 'tax', 206: 'near', 207: 'alone', 208: 'wrong', 209: 'do', 210: 'band-aid', 211: 'help', 212: 'tomorrow', 213: 'forbidden', 214: 'pillow', 215: 'bed', 216: 'slow', 217: 'eat', 218: 'cook', 219: 'star', 220: 'absent', 221: 'road', 222: 'tired', 223: 'egg', 224: 'time', 225: 'difficult'}\n"
     ]
    }
   ],
   "source": [
    "print(class_id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5af8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(vid_path, frames_cap, transforms=None):\n",
    "    \"\"\"Extract and transform video frames\n",
    "\n",
    "    Parameters:\n",
    "    vid_path (str): path to video file\n",
    "    frames_cap (int): number of frames to extract, evenly spaced\n",
    "    transforms (torchvision.transforms, optional): transformations to apply to frame\n",
    "\n",
    "    Returns:\n",
    "    list of numpy.array: vid_arr\n",
    "\n",
    "    \"\"\"\n",
    "    vid_arr = []\n",
    "    with av.open(vid_path) as container:\n",
    "        stream = container.streams.video[0]\n",
    "        n_frames = stream.frames\n",
    "        remainder = n_frames % frames_cap\n",
    "        interval = n_frames // frames_cap\n",
    "        take_frame_idx = 0\n",
    "        for frame_no, frame in enumerate(container.decode(stream)):\n",
    "            if frame_no == take_frame_idx:\n",
    "                img = frame.to_image()\n",
    "                if transforms:\n",
    "                    img = transforms(img)\n",
    "                vid_arr.append(np.array(img))\n",
    "                if remainder > 0:\n",
    "                    take_frame_idx += 1\n",
    "                    remainder -= 1\n",
    "                take_frame_idx += interval\n",
    "    if len(vid_arr) < frames_cap:\n",
    "        raise ValueError(f\"video with path '{vid_path}' is too short, please make sure that video has >={frames_cap} frames\")\n",
    "    return vid_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3c41124",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a00e70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Conv3D import r2plus1d_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "819663b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m r2plus1d_18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m226\u001b[39m)\n\u001b[0;32m      2\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models3d/final_masked2/11.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model_state_dict'"
     ]
    }
   ],
   "source": [
    "model = r2plus1d_18(pretrained=True, num_classes=226)\n",
    "checkpoint = torch.load(\"saved_models3d/final_masked2/11.pt\", map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11989550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = r2plus1d_18(pretrained=True, num_classes=226)\n",
    "#checkpoint = torch.load(\"saved_models/cnn_lstm_512_6_1_512_drop80_weightd8/18-checkpoint.pt\")\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf826f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(vid, transforms = None, frames_cap = 30):\n",
    "    \n",
    "    selector = fix_frame(len(vid), frames_cap)\n",
    "    output = []\n",
    "    for e,frame in enumerate(vid):\n",
    "        if e+1 in selector:\n",
    "            output.append(frame)\n",
    "    \n",
    "    # edge case\n",
    "    if len(vid) < frames_cap:\n",
    "        remainder = frames_cap - len(vid)\n",
    "        # take last frame\n",
    "        last_frame = vid[-1]\n",
    "        for _ in range(remainder):\n",
    "            output.append(last_frame)\n",
    "        \n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d47812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(rbg_vid, depth_vid):\n",
    "    \"\"\"\n",
    "    input\n",
    "        - path for rbg\n",
    "        - path for depth\n",
    "    output\n",
    "        - array of numpy arrays\n",
    "    \"\"\"\n",
    "    rbg_arr = []\n",
    "    container_rbg = av.open(rbg_vid)\n",
    "\n",
    "    for packet in container_rbg.demux():\n",
    "        for frame in packet.decode():\n",
    "            rbg_arr.append(np.array(frame.to_image()))\n",
    "\n",
    "    depth_arr = []\n",
    "    container_depth = av.open(depth_vid)\n",
    "\n",
    "    for packet in container_depth.demux():\n",
    "        for frame in packet.decode():\n",
    "            depth_arr.append(np.array(frame.to_image()))\n",
    "            \n",
    "    # pose estimation\n",
    "    #rbg_arr = pose_styling(rbg_arr)\n",
    "\n",
    "    # display - correct color orientation\n",
    "    overlay_arr = []\n",
    "    for i in range(len(rbg_arr)):\n",
    "        c = cv2.cvtColor(rbg_arr[i], cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(depth_arr[i], cv2.COLOR_BGR2GRAY)\n",
    "        overlay = cv2.bitwise_and(c,c, mask= gray)\n",
    "        \n",
    "        # resize and reshape\n",
    "        overlay = cv2.resize(overlay, (256,256))\n",
    "        \n",
    "        # convert from (h , w, c) to (c, h, w)\n",
    "        overlay_reshape = np.transpose(overlay, (2, 0, 1))\n",
    "        \n",
    "        overlay_arr.append(overlay_reshape)\n",
    "        \n",
    "    return np.array(overlay_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_frame(input_frame: int, output_frame: int) -> set:\n",
    "    '''\n",
    "    input\n",
    "        - number of input frames\n",
    "        - number of output frames\n",
    "    output\n",
    "        - a set of frames\n",
    "    '''\n",
    "    if input_frame < output_frame:\n",
    "        print('Spotted video that have input frame: {} < output frame: {}'.format(input_frame, output_frame))\n",
    "        return set([i for i in range(1, input_frame+1)])\n",
    "    \n",
    "    # create array to pick from\n",
    "    pick_arr = []\n",
    "    for i in range(1,input_frame+1):\n",
    "        for r in range(output_frame):\n",
    "            pick_arr.append(i)\n",
    "            \n",
    "    # decide on index to capture\n",
    "    # e.g. frame 58//2 = 29\n",
    "    ind = input_frame//2\n",
    "    \n",
    "    # capture frame\n",
    "    output = set()\n",
    "    i = 1\n",
    "    batch = 0\n",
    "    while (i + (batch * input_frame)) < len(pick_arr):\n",
    "        if i == ind:\n",
    "            output.add(pick_arr[i + (batch * input_frame) - 1])\n",
    "        i+=1\n",
    "        if i == input_frame + 1:\n",
    "            i = 1\n",
    "            batch += 1\n",
    "    if len(output) != output_frame:\n",
    "        raise ValueError('output does not have the same frame requirements. output: {}, required: {}'.format(len(output), output_frame))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6defd5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test_video(vid_name):\n",
    "    \"\"\"Load video from dataset and pass video to model\n",
    "\n",
    "    Parameters:\n",
    "    vid_name (str): video name to display\n",
    "\n",
    "    \"\"\"\n",
    "    transforms_compose = transforms.Compose([transforms.Resize(256), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "    vid_color_path = f\"{test_dir}/{vid_name}_color.mp4\"\n",
    "    vid_depth_path = f\"{test_dir}/{vid_name}_depth.mp4\"\n",
    "    rgb_arr = extract_frames(vid_color_path, 30, transforms=transforms_compose)\n",
    "    vid_arr = np.array(rgb_arr)\n",
    "    vid_arr = vid_arr/255\n",
    "    #vid_arr = masking(vid_color_path, vid_depth_path)\n",
    "    #vid_arr = extract_frames(vid_arr, 30)\n",
    "    vid_arr = torch.from_numpy(vid_arr).float()\n",
    "    #vid_arr = vid_arr.permute(1, 0, 2, 3)\n",
    "    vid_arr = vid_arr.unsqueeze(0)\n",
    "    predict_id = model.forward(vid_arr)\n",
    "    predict_id = torch.max(predict_id, 1)[1].item()\n",
    "    ground_truth_id = test_label[f\"{test_dir}/{vid_name}\"]\n",
    "    return predict_id, class_id_to_label[predict_id], ground_truth_id, class_id_to_label[ground_truth_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bc77862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3739/3739 [52:01<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the test set and perform predictions on each sample. Add their ground truths and predictions to lists\n",
    "df = pd.read_csv(\"dataset/test_labels.csv\", names=[\"video_name\", \"class_id\"])\n",
    "predict_ids = []\n",
    "predict_labels = []\n",
    "ground_truth_ids = []\n",
    "ground_truth_labels = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    predict_id, predict_label, ground_truth_id, ground_truth_label = load_and_test_video(row['video_name'])\n",
    "    predict_ids.append(predict_id)\n",
    "    predict_labels.append(predict_label)\n",
    "    ground_truth_ids.append(ground_truth_id)\n",
    "    ground_truth_labels.append(ground_truth_label)\n",
    "\n",
    "# Load the test set and perform predictions on each sample. Add their ground truths and predictions to lists\n",
    "\n",
    "df['predict_id'] = predict_ids\n",
    "df['predict_label'] = predict_labels\n",
    "df['ground_truth_id'] = ground_truth_ids\n",
    "df['ground_truth_label'] = ground_truth_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae1a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predict_id'] = predict_ids\n",
    "df['predict_label'] = predict_labels\n",
    "df['ground_truth_id'] = ground_truth_ids\n",
    "df['ground_truth_label'] = ground_truth_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69cb22da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>predict_id</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>ground_truth_id</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>signer34_sample1</td>\n",
       "      <td>133</td>\n",
       "      <td>175</td>\n",
       "      <td>you</td>\n",
       "      <td>133</td>\n",
       "      <td>guest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>signer34_sample2</td>\n",
       "      <td>61</td>\n",
       "      <td>164</td>\n",
       "      <td>request</td>\n",
       "      <td>61</td>\n",
       "      <td>retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>signer34_sample3</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>hammer</td>\n",
       "      <td>32</td>\n",
       "      <td>together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>signer34_sample4</td>\n",
       "      <td>169</td>\n",
       "      <td>39</td>\n",
       "      <td>teapot</td>\n",
       "      <td>169</td>\n",
       "      <td>champion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>signer34_sample5</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>show</td>\n",
       "      <td>77</td>\n",
       "      <td>show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>signer30_sample658</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>salary</td>\n",
       "      <td>125</td>\n",
       "      <td>salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>signer30_sample659</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>ceiling</td>\n",
       "      <td>191</td>\n",
       "      <td>ceiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>signer30_sample660</td>\n",
       "      <td>96</td>\n",
       "      <td>220</td>\n",
       "      <td>absent</td>\n",
       "      <td>96</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>signer30_sample661</td>\n",
       "      <td>59</td>\n",
       "      <td>142</td>\n",
       "      <td>wood</td>\n",
       "      <td>59</td>\n",
       "      <td>glove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>signer30_sample662</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>full</td>\n",
       "      <td>63</td>\n",
       "      <td>meal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              video_name  class_id  predict_id predict_label  ground_truth_id  \\\n",
       "0       signer34_sample1       133         175           you              133   \n",
       "1       signer34_sample2        61         164       request               61   \n",
       "2       signer34_sample3        32          40        hammer               32   \n",
       "3       signer34_sample4       169          39        teapot              169   \n",
       "4       signer34_sample5        77          77          show               77   \n",
       "...                  ...       ...         ...           ...              ...   \n",
       "3734  signer30_sample658       125         125        salary              125   \n",
       "3735  signer30_sample659       191         191       ceiling              191   \n",
       "3736  signer30_sample660        96         220        absent               96   \n",
       "3737  signer30_sample661        59         142          wood               59   \n",
       "3738  signer30_sample662        63          53          full               63   \n",
       "\n",
       "     ground_truth_label  \n",
       "0                 guest  \n",
       "1               retired  \n",
       "2              together  \n",
       "3              champion  \n",
       "4                  show  \n",
       "...                 ...  \n",
       "3734             salary  \n",
       "3735            ceiling  \n",
       "3736           medicine  \n",
       "3737              glove  \n",
       "3738               meal  \n",
       "\n",
       "[3739 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c6a9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         sister       0.40      0.25      0.31        16\n",
      "          hurry       0.00      0.00      0.00        16\n",
      "         hungry       0.00      0.00      0.00        17\n",
      "enjoy_your_meal       0.14      0.18      0.16        17\n",
      "        brother       0.38      0.18      0.24        17\n",
      "           tree       0.19      0.53      0.28        17\n",
      "          heavy       0.21      0.18      0.19        17\n",
      "            cry       0.00      0.00      0.00        17\n",
      "         family       0.05      0.12      0.07        17\n",
      "           wise       0.00      0.00      0.00        17\n",
      "         unwise       0.03      0.12      0.05        17\n",
      "            kin       0.10      0.06      0.08        16\n",
      "       shopping       0.04      0.13      0.06        15\n",
      "            key       0.00      0.00      0.00        16\n",
      "         mother       0.14      0.06      0.08        17\n",
      "         friend       0.56      0.33      0.42        15\n",
      "        ataturk       0.00      0.00      0.00        14\n",
      "           shoe       0.00      0.00      0.00        16\n",
      "         mirror       0.02      0.12      0.03        17\n",
      "           same       0.00      0.00      0.00        17\n",
      "         father       0.07      0.06      0.06        16\n",
      "         garden       0.33      0.24      0.28        17\n",
      "           look       0.00      0.00      0.00        17\n",
      "          honey       0.00      0.00      0.00        16\n",
      "          glass       0.14      0.19      0.16        16\n",
      "           flag       0.04      0.12      0.06        16\n",
      "          feast       0.35      0.53      0.42        17\n",
      "           baby       0.05      0.06      0.05        17\n",
      "         single       0.20      0.12      0.15        17\n",
      "           wait       0.30      0.18      0.22        17\n",
      "              I       0.09      0.12      0.10        17\n",
      "         petrol       0.45      0.29      0.36        17\n",
      "       together       0.29      0.12      0.17        17\n",
      "         inform       0.25      0.65      0.36        17\n",
      "             we       0.04      0.06      0.05        17\n",
      "           work       0.00      0.00      0.00        16\n",
      "      wednesday       0.00      0.00      0.00        17\n",
      "           fork       0.33      0.29      0.31        17\n",
      "            tea       0.16      0.29      0.20        17\n",
      "         teapot       0.15      0.25      0.19        16\n",
      "         hammer       0.03      0.06      0.04        17\n",
      "           ugly       0.03      0.06      0.04        17\n",
      "          child       0.00      0.00      0.00        17\n",
      "           soup       0.11      0.18      0.13        17\n",
      "         friday       0.43      0.18      0.25        17\n",
      "       saturday       1.00      0.12      0.21        17\n",
      "         wallet       1.00      0.12      0.21        17\n",
      "         minute       0.20      0.07      0.11        14\n",
      "    grandfather       0.29      0.47      0.36        17\n",
      "         change       0.06      0.06      0.06        17\n",
      "         topple       0.27      0.19      0.22        16\n",
      "     government       0.00      0.00      0.00        16\n",
      "         doctor       0.00      0.00      0.00        10\n",
      "           full       0.00      0.00      0.00        17\n",
      "        wedding       0.00      0.00      0.00        16\n",
      "      yesterday       0.00      0.00      0.00        17\n",
      "          enemy       0.06      0.06      0.06        16\n",
      "           wall       0.38      0.19      0.25        16\n",
      "       pharmacy       0.15      0.18      0.16        17\n",
      "          glove       0.00      0.00      0.00        17\n",
      "          labor       0.09      0.36      0.15        14\n",
      "        retired       0.14      0.24      0.18        17\n",
      "           male       0.00      0.00      0.00        17\n",
      "           meal       0.50      0.12      0.19        17\n",
      "          house       0.43      0.18      0.25        17\n",
      "            yes       0.00      0.00      0.00        15\n",
      "        married       0.00      0.00      0.00        16\n",
      "       memorize       0.67      0.13      0.22        15\n",
      "       elephant       0.17      0.25      0.21        16\n",
      "     photograph       0.62      0.33      0.43        15\n",
      "       football       0.40      0.47      0.43        17\n",
      "           past       0.00      0.00      0.00        16\n",
      "       get_well       0.20      0.12      0.15        16\n",
      "          bring       0.20      0.06      0.09        17\n",
      "           lake       0.00      0.00      0.00        16\n",
      "          shirt       0.09      0.06      0.07        16\n",
      "            see       0.00      0.00      0.00        17\n",
      "           show       0.38      0.50      0.43        16\n",
      "          laugh       0.06      0.06      0.06        17\n",
      "    lightweight       0.17      0.09      0.12        11\n",
      "          right       0.00      0.00      0.00        17\n",
      "         carpet       0.33      0.12      0.17        17\n",
      "            ill       0.25      0.35      0.29        17\n",
      "       hospital       1.00      0.35      0.52        17\n",
      "          fault       0.42      0.29      0.34        17\n",
      "          towel       0.32      0.35      0.33        17\n",
      "             no       0.00      0.00      0.00        17\n",
      "congratulations       0.67      0.14      0.24        14\n",
      "         animal       1.00      0.44      0.61        16\n",
      "           gift       0.15      0.12      0.13        17\n",
      "          halal       0.38      0.18      0.24        17\n",
      "         always       0.00      0.00      0.00        17\n",
      "          never       0.17      0.18      0.17        17\n",
      "        goodbye       0.00      0.00      0.00        17\n",
      "          drink       0.00      0.00      0.00        17\n",
      "         needle       0.25      0.07      0.11        15\n",
      "       medicine       0.00      0.00      0.00        17\n",
      " not_interested       0.00      0.00      0.00        17\n",
      "          light       0.02      0.31      0.04        16\n",
      "           push       0.57      0.24      0.33        17\n",
      "           good       0.00      0.00      0.00        17\n",
      "         escape       0.18      0.24      0.21        17\n",
      "      breakfast       0.27      0.65      0.38        17\n",
      "         pencil       0.00      0.00      0.00        16\n",
      "       radiator       0.50      0.12      0.19        17\n",
      "           door       0.50      0.24      0.32        17\n",
      "        sibling       0.19      0.18      0.18        17\n",
      "     crossroads       0.00      0.00      0.00        17\n",
      "       accident       0.00      0.00      0.00        16\n",
      "           belt       0.00      0.00      0.00        17\n",
      "        if_only       0.05      0.12      0.07        17\n",
      "            who       0.18      0.24      0.21        17\n",
      "       identity       0.27      0.18      0.21        17\n",
      "           rent       0.40      0.12      0.18        17\n",
      "           book       1.00      0.12      0.21        17\n",
      "          mince       0.55      0.38      0.44        16\n",
      "         female       0.00      0.00      0.00        17\n",
      "          smell       0.00      0.00      0.00        14\n",
      "        cologne       0.56      0.60      0.58        15\n",
      "           coal       0.29      0.24      0.26        17\n",
      "            dog       0.31      0.24      0.27        17\n",
      "         bridge       1.00      0.18      0.30        17\n",
      "            bad       0.00      0.00      0.00        17\n",
      "            lap       0.75      0.18      0.29        17\n",
      "          stain       0.29      0.24      0.26        17\n",
      "         salary       0.50      0.18      0.26        17\n",
      "       scissors       0.08      0.07      0.07        15\n",
      "          tongs       0.14      0.31      0.20        16\n",
      "   god_preserve       0.50      0.18      0.26        17\n",
      "          angel       0.33      0.18      0.23        17\n",
      "     be_pleased       0.86      0.35      0.50        17\n",
      "         napkin       0.17      0.07      0.10        14\n",
      "         stairs       0.19      0.20      0.19        15\n",
      "          guest       0.00      0.00      0.00        17\n",
      "        manager       0.14      0.24      0.17        17\n",
      "            tap       0.14      0.24      0.17        17\n",
      "            how       0.17      0.06      0.09        16\n",
      "            why       0.00      0.00      0.00        17\n",
      "          where       0.00      0.00      0.00        17\n",
      "    grandmother       0.00      0.00      0.00        17\n",
      "           oven       0.05      0.06      0.05        17\n",
      "           room       0.18      0.12      0.14        17\n",
      "           wood       0.10      0.06      0.07        17\n",
      "        teacher       0.00      0.00      0.00        17\n",
      "         school       0.00      0.00      0.00        17\n",
      "       olympiad       0.00      0.00      0.00        17\n",
      "           nope       0.00      0.00      0.00        17\n",
      "       allright       0.00      0.00      0.00        17\n",
      "           they       0.01      0.06      0.02        17\n",
      "         forest       0.03      0.53      0.06        17\n",
      "        fasting       0.04      0.19      0.07        16\n",
      "      apologize       0.67      0.47      0.55        17\n",
      "         cotton       0.00      0.00      0.00        17\n",
      "       trousers       0.50      0.12      0.19        17\n",
      "          money       0.67      0.12      0.20        17\n",
      "       pastrami       0.00      0.00      0.00        17\n",
      "         potato       0.00      0.00      0.00        17\n",
      "         sunday       0.20      0.06      0.09        17\n",
      "         monday       0.75      0.18      0.29        17\n",
      "         window       0.37      0.41      0.39        17\n",
      "       thursday       0.06      0.12      0.08        17\n",
      "         picnic       0.00      0.00      0.00        17\n",
      "         police       0.00      0.00      0.00        17\n",
      "     psychology       1.00      0.12      0.21        17\n",
      "        request       0.17      0.29      0.21        17\n",
      "           hour       0.00      0.00      0.00        17\n",
      "           soap       0.00      0.00      0.00        17\n",
      "          sauce       0.25      0.38      0.30        16\n",
      "        tuesday       0.12      0.06      0.08        17\n",
      "       champion       0.38      0.18      0.24        17\n",
      "            hat       0.00      0.00      0.00        17\n",
      "            war       0.75      0.18      0.29        17\n",
      "          sugar       0.00      0.00      0.00        11\n",
      "             hi       0.00      0.00      0.00        17\n",
      "       umbrella       0.21      0.24      0.22        17\n",
      "            you       0.03      0.12      0.05        17\n",
      "           bill       0.33      0.07      0.11        15\n",
      "           free       0.80      0.24      0.36        17\n",
      "          voice       0.00      0.00      0.00        17\n",
      "           love       0.33      0.12      0.17        17\n",
      "           evil       0.15      0.24      0.18        17\n",
      "         border       0.42      0.29      0.34        17\n",
      "            you       0.08      0.06      0.07        16\n",
      "            say       0.00      0.00      0.00        16\n",
      "        promise       0.00      0.00      0.00        17\n",
      "           milk       0.12      0.24      0.16        17\n",
      "           okay       0.00      0.00      0.00        16\n",
      "           comb       0.38      0.18      0.24        17\n",
      "           date       0.09      0.06      0.07        17\n",
      "        holiday       0.20      0.06      0.09        17\n",
      "          sweet       1.00      0.12      0.21        17\n",
      "        ceiling       0.02      0.18      0.04        17\n",
      "         danger       0.07      0.06      0.06        17\n",
      "      telephone       0.21      0.24      0.22        17\n",
      "         scales       0.04      0.12      0.05        17\n",
      "         tailor       0.20      0.13      0.16        15\n",
      "         thanks       0.33      0.24      0.28        17\n",
      "    screwdriver       0.00      0.00      0.00        17\n",
      "         turkey       0.44      0.25      0.32        16\n",
      "         orange       0.00      0.00      0.00        17\n",
      "         toilet       0.03      0.06      0.04        17\n",
      "          flour       0.36      0.29      0.32        17\n",
      "            far       0.44      0.25      0.32        16\n",
      "            sad       0.00      0.00      0.00        17\n",
      "       existing       0.00      0.00      0.00        17\n",
      "            tax       0.07      0.06      0.06        17\n",
      "           near       0.00      0.00      0.00        14\n",
      "          alone       0.67      0.12      0.20        17\n",
      "          wrong       0.00      0.00      0.00        17\n",
      "             do       0.00      0.00      0.00        17\n",
      "       band-aid       0.20      0.06      0.09        17\n",
      "           help       0.21      0.21      0.21        14\n",
      "       tomorrow       0.20      0.06      0.09        17\n",
      "      forbidden       0.17      0.18      0.17        17\n",
      "         pillow       0.33      0.12      0.17        17\n",
      "            bed       0.00      0.00      0.00        17\n",
      "           slow       1.00      0.06      0.11        17\n",
      "            eat       0.04      0.25      0.08        16\n",
      "           cook       0.04      0.29      0.07        17\n",
      "           star       0.20      0.18      0.19        17\n",
      "         absent       0.02      0.12      0.04        17\n",
      "           road       0.00      0.00      0.00        17\n",
      "          tired       0.11      0.06      0.08        17\n",
      "            egg       0.00      0.00      0.00        17\n",
      "           time       0.50      0.18      0.26        17\n",
      "      difficult       0.00      0.00      0.00        17\n",
      "\n",
      "       accuracy                           0.13      3739\n",
      "      macro avg       0.20      0.13      0.13      3739\n",
      "   weighted avg       0.20      0.13      0.13      3739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Hadi\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = [class_id_to_label[key] if key in class_id_to_label.keys() else 0 for key in range(226)]\n",
    "print(classification_report(ground_truth_ids, predict_ids, target_names=target_names))\n",
    "report = classification_report(ground_truth_ids, predict_ids,target_names=target_names, output_dict=True)\n",
    "df_classification_report = pd.DataFrame(report).transpose()\n",
    "df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "df_classification_report.to_csv('normal_report.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total test data:{len(df)}')\n",
    "cm = confusion_matrix(ground_truth_ids, predict_ids)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(target_names))\n",
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('masked_CNN_prediction.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764b7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
