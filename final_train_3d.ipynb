{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a22b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# misc\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "\n",
    "# preprocessing \n",
    "import av\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# helper classes and functions\n",
    "from train_model import train\n",
    "from model import CNN_LSTM, VGG_LSTM\n",
    "from Conv3D import r2plus1d_18\n",
    "from collections import OrderedDict\n",
    "\n",
    "# logging\n",
    "import os\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd1413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create relevant directories\n",
    "\n",
    "# create dir to save logs if it does not exist\n",
    "if not os.path.exists(\"log3d\"):\n",
    "    os.mkdir(\"log3d\")\n",
    "\n",
    "# create dir to save runs if it does not exist\n",
    "if not os.path.exists(\"runs3d\"):\n",
    "    os.mkdir(\"runs3d\")\n",
    "\n",
    "# create dir to save models if it does not exist\n",
    "if not os.path.exists(\"saved_models3d\"):\n",
    "    os.mkdir(\"saved_models3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "674e93a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging to file...\n"
     ]
    }
   ],
   "source": [
    "log_path = \"log/cnnlstm_{:%Y-%m-%d_%H-%M-%S}.log\".format(datetime.now())\n",
    "sum_path = \"runs/cnnlstm_{:%Y-%m-%d_%H-%M-%S}\".format(datetime.now())\n",
    "\n",
    "# Log to file & tensorboard writer\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s', handlers=[logging.FileHandler(log_path), logging.StreamHandler()])\n",
    "logger = logging.getLogger('signo-lingo')\n",
    "logger.info('Logging to file...')\n",
    "writer = SummaryWriter(sum_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66ae90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a4615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "train_dir = f'{data_dir}/train'\n",
    "val_dir = f'{data_dir}/val'\n",
    "test_dir = f'{data_dir}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98d2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"dataset\"\n",
    "\n",
    "train_path = [os.path.join('{}/train'.format(root_path), f) for f in os.listdir('{}/train'.format(root_path))]\n",
    "val_path = [os.path.join('{}/val'.format(root_path), f) for f in os.listdir('{}/val'.format(root_path))]\n",
    "test_path = [os.path.join('{}/test'.format(root_path), f) for f in os.listdir('{}/test'.format(root_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71eb022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All labels\n",
    "train_label_df = pd.read_csv(r'{}/train_labels.csv'.format(root_path), header=None)\n",
    "test_label_df = pd.read_csv(r'{}/test_labels.csv'.format(root_path), header=None)\n",
    "val_label_df = pd.read_csv(r'{}/val_labels.csv'.format(root_path), header=None)\n",
    "\n",
    "# convert all into hashmap - key = u_vid_name , value = label\n",
    "\n",
    "train_label = {k[0]: k[1] for k in train_label_df.values.tolist()}\n",
    "test_label = {k[0]: k[1] for k in test_label_df.values.tolist()}\n",
    "val_label = {k[0]: k[1] for k in val_label_df.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ed0c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique label: 226\n"
     ]
    }
   ],
   "source": [
    "total_label = pd.read_csv(r'{}/ClassId.csv'.format(root_path))\n",
    "u_len_label = len(total_label['ClassId'].unique())\n",
    "print(\"total unique label:\", u_len_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ba0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick fix frames\n",
    "'''\n",
    "e.g.\n",
    "input_frame = 5, output_frame = 3\n",
    "\n",
    "steps 1. create an array and multiply each frame by output factor\n",
    "    [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5] \n",
    "    \n",
    "step 2. Divide by output section\n",
    "    [1, 1, 1, 2, 2, | 2, 3, 3, 3, 4, | 4, 4, 5, 5, 5]\n",
    "    \n",
    "step 3. Find the center index to pick\n",
    "    5 // 2 = 2\n",
    "    \n",
    "step 4. Select center index from each section\n",
    "    [1, 1*, 1, 2, 2, | 2, 3*, 3, 3, 4, | 4, 4*, 5, 5, 5]\n",
    "    \n",
    "step 5. Return a set of those index\n",
    "    set([1, 3, 4])\n",
    "'''\n",
    "def fix_frame(input_frame: int, output_frame: int) -> set:\n",
    "    '''\n",
    "    input\n",
    "        - number of input frames\n",
    "        - number of output frames\n",
    "    output\n",
    "        - a set of frames\n",
    "    '''\n",
    "    if input_frame < output_frame:\n",
    "        print('Spotted video that have input frame: {} < output frame: {}'.format(input_frame, output_frame))\n",
    "        return set([i for i in range(1, input_frame+1)])\n",
    "    \n",
    "    # create array to pick from\n",
    "    pick_arr = []\n",
    "    for i in range(1,input_frame+1):\n",
    "        for r in range(output_frame):\n",
    "            pick_arr.append(i)\n",
    "            \n",
    "    # decide on index to capture\n",
    "    # e.g. frame 58//2 = 29\n",
    "    ind = input_frame//2\n",
    "    \n",
    "    # capture frame\n",
    "    output = set()\n",
    "    i = 1\n",
    "    batch = 0\n",
    "    while (i + (batch * input_frame)) < len(pick_arr):\n",
    "        if i == ind:\n",
    "            output.add(pick_arr[i + (batch * input_frame) - 1])\n",
    "        i+=1\n",
    "        if i == input_frame + 1:\n",
    "            i = 1\n",
    "            batch += 1\n",
    "    if len(output) != output_frame:\n",
    "        raise ValueError('output does not have the same frame requirements. output: {}, required: {}'.format(len(output), output_frame))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fa0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(vid, transforms = None, frames_cap = 30):\n",
    "    \n",
    "    selector = fix_frame(len(vid), frames_cap)\n",
    "    output = []\n",
    "    for e,frame in enumerate(vid):\n",
    "        if e+1 in selector:\n",
    "            output.append(frame)\n",
    "    \n",
    "    # edge case\n",
    "    if len(vid) < frames_cap:\n",
    "        remainder = frames_cap - len(vid)\n",
    "        # take last frame\n",
    "        last_frame = vid[-1]\n",
    "        for _ in range(remainder):\n",
    "            output.append(last_frame)\n",
    "        \n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8fd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask rbg image\n",
    "def masking(rbg_vid, depth_vid):\n",
    "    \"\"\"\n",
    "    input\n",
    "        - path for rbg\n",
    "        - path for depth\n",
    "    output\n",
    "        - array of numpy arrays\n",
    "    \"\"\"\n",
    "    rbg_arr = []\n",
    "    container_rbg = av.open(rbg_vid)\n",
    "\n",
    "    for packet in container_rbg.demux():\n",
    "        for frame in packet.decode():\n",
    "            rbg_arr.append(np.array(frame.to_image()))\n",
    "\n",
    "    depth_arr = []\n",
    "    container_depth = av.open(depth_vid)\n",
    "\n",
    "    for packet in container_depth.demux():\n",
    "        for frame in packet.decode():\n",
    "            depth_arr.append(np.array(frame.to_image()))\n",
    "            \n",
    "    # pose estimation\n",
    "    #rbg_arr = pose_styling(rbg_arr)\n",
    "\n",
    "    # display - correct color orientation\n",
    "    overlay_arr = []\n",
    "    for i in range(len(rbg_arr)):\n",
    "        c = cv2.cvtColor(rbg_arr[i], cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(depth_arr[i], cv2.COLOR_BGR2GRAY)\n",
    "        overlay = cv2.bitwise_and(c,c, mask= gray)\n",
    "        \n",
    "        # resize and reshape\n",
    "        overlay = cv2.resize(overlay, (256,256))\n",
    "        \n",
    "        # convert from (h , w, c) to (c, h, w)\n",
    "        overlay_reshape = np.transpose(overlay, (2, 0, 1))\n",
    "        \n",
    "        overlay_arr.append(overlay_reshape)\n",
    "        \n",
    "    return np.array(overlay_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a562280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turkish_Dataset(Dataset):\n",
    "    def __init__(self, paths, labels):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self._get_unique()\n",
    "        \n",
    "    def _get_unique(self):\n",
    "        u_vid_depth = {}\n",
    "        u_vid_color = {}\n",
    "        u_vid = set()\n",
    "        for path in self.paths:\n",
    "            vid = path.split(\"\\\\\")[-1].split(\".\")[0] # train\\\\signer0_sample1_color.mp4 or train\\\\signer0_sample1_depth.mp4\n",
    "            vid_split = vid.split(\"_\")\n",
    "            vid_type = vid_split[-1] # color or depth\n",
    "            vid_name = \"_\".join(vid_split[:-1]) # signer0_sample1_color\n",
    "            if vid_type == \"color\":\n",
    "                u_vid_color[vid_name] = path\n",
    "            elif vid_type == \"depth\":\n",
    "                u_vid_depth[vid_name] = path\n",
    "            else:\n",
    "                raise ValueError('Detected vid type as neither color nor depth. type is', vid_type)\n",
    "            u_vid.add(vid_name)\n",
    "        self.u_vid_depth = u_vid_depth\n",
    "        self.u_vid_color = u_vid_color\n",
    "        self.u_vid = list(u_vid)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        vid_name = self.u_vid[index]\n",
    "        vid_label = self.labels[vid_name]\n",
    "        \n",
    "        vid_color = self.u_vid_color[vid_name]\n",
    "        vid_depth = self.u_vid_depth[vid_name]\n",
    "        \n",
    "        # preprocessing\n",
    "        vid_arr = masking(vid_color, vid_depth)\n",
    "#         if (len(vid_arr) < 30):\n",
    "#             print('{} has {} frames'.format(vid_name, len(vid_arr)))\n",
    "        vid_arr = extract_frames(vid_arr, 30)\n",
    "\n",
    "        # create one-hot-encoding for label\n",
    "        #label = np.zeros(u_len_label)\n",
    "        label = np.zeros(226)\n",
    "        label[vid_label] = 1\n",
    "        \n",
    "        # convert arr to tensors\n",
    "        vid_arr = torch.from_numpy(vid_arr).float()\n",
    "        vid_arr = vid_arr.permute(1, 0, 2, 3)\n",
    "        label = torch.from_numpy(label).long().argmax()\n",
    "        \n",
    "        # return masked video array and label\n",
    "        return vid_arr, label\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.u_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66749bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 30\n",
    "transforms_compose = transforms.Compose([transforms.Resize(256), \n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.5], std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "719eeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset\n",
    "ld_train = Turkish_Dataset(train_path, train_label)\n",
    "\n",
    "# show image but clip rbg values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac27264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of first array torch.Size([3, 30, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# create test dataset\n",
    "ld_test = Turkish_Dataset(test_path, test_label)\n",
    "print(\"shape of first array\", ld_test[0][0].shape)\n",
    "\n",
    "# show image but clip rbg values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba185b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of first array torch.Size([3, 30, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# create val dataset\n",
    "ld_val = Turkish_Dataset(val_path, val_label)\n",
    "print(\"shape of first array\", ld_val[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f70b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 1\n",
    "bs_test = 1\n",
    "bs_val = 1\n",
    "train_loader = DataLoader(ld_train, batch_size = bs_train, shuffle = True)\n",
    "test_loader = DataLoader(ld_test, batch_size = bs_test, shuffle = True)\n",
    "val_loader = DataLoader(ld_val, batch_size = bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5609fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = r2plus1d_18(pretrained=True, num_classes=500)\n",
    "    # load pretrained\n",
    "checkpoint = torch.load('slr_resnet2d+1.pth')\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    name = k[7:] # remove 'module.'\n",
    "    new_state_dict[name]=v\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.fc1 = nn.Linear(model.fc1.in_features, 226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91ff3e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "r2plus1d_18                                        [1, 226]                  --\n",
       "├─Sequential: 1-1                                  [1, 512, 1, 1, 1]         --\n",
       "│    └─R2Plus1dStem: 2-1                           [1, 64, 30, 128, 128]     --\n",
       "│    │    └─Conv3d: 3-1                            [1, 45, 30, 128, 128]     6,615\n",
       "│    │    └─BatchNorm3d: 3-2                       [1, 45, 30, 128, 128]     90\n",
       "│    │    └─SiLU: 3-3                              [1, 45, 30, 128, 128]     --\n",
       "│    │    └─Conv3d: 3-4                            [1, 64, 30, 128, 128]     8,640\n",
       "│    │    └─BatchNorm3d: 3-5                       [1, 64, 30, 128, 128]     128\n",
       "│    │    └─SiLU: 3-6                              [1, 64, 30, 128, 128]     --\n",
       "│    └─Sequential: 2-2                             [1, 64, 30, 128, 128]     --\n",
       "│    │    └─BasicBlock: 3-7                        [1, 64, 30, 128, 128]     222,016\n",
       "│    │    └─BasicBlock: 3-8                        [1, 64, 30, 128, 128]     222,016\n",
       "│    └─Sequential: 2-3                             [1, 128, 15, 64, 64]      --\n",
       "│    │    └─BasicBlock: 3-9                        [1, 128, 15, 64, 64]      583,960\n",
       "│    │    └─BasicBlock: 3-10                       [1, 128, 15, 64, 64]      886,400\n",
       "│    └─Sequential: 2-4                             [1, 256, 8, 32, 32]       --\n",
       "│    │    └─BasicBlock: 3-11                       [1, 256, 8, 32, 32]       2,332,464\n",
       "│    │    └─BasicBlock: 3-12                       [1, 256, 8, 32, 32]       3,542,272\n",
       "│    └─Sequential: 2-5                             [1, 512, 4, 16, 16]       --\n",
       "│    │    └─BasicBlock: 3-13                       [1, 512, 4, 16, 16]       9,333,092\n",
       "│    │    └─BasicBlock: 3-14                       [1, 512, 4, 16, 16]       14,162,432\n",
       "│    └─AdaptiveAvgPool3d: 2-6                      [1, 512, 1, 1, 1]         --\n",
       "├─Dropout: 1-2                                     [1, 512]                  --\n",
       "├─Linear: 1-3                                      [1, 226]                  115,938\n",
       "====================================================================================================\n",
       "Total params: 31,416,063\n",
       "Trainable params: 31,416,063\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 401.29\n",
       "====================================================================================================\n",
       "Input size (MB): 23.59\n",
       "Forward/backward pass size (MB): 9891.07\n",
       "Params size (MB): 125.66\n",
       "Estimated Total Size (MB): 10040.33\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 3, 30, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64f22dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 1000\n",
    "optimizer_lr = 1e-5\n",
    "save_dir = \"saved_models3d/final_masked2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08bbf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f970a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################Training Started######################\n",
      "Epoch 1\n",
      "100%|██████████| 28123/28123 [5:49:44<00:00,  1.34batch/s, accuracy=0, loss=5.25]      \n",
      "Average Training Loss of Epoch 1: 5.324275 | Acc: 0.90%\n",
      "100%|██████████| 4413/4413 [23:05<00:00,  3.19batch/s, accuracy=0, loss=5.44]\n",
      "Average Validation Loss of Epoch 1: 5.457649 | Acc: 0.25%\n",
      "####################Epoch 1 Model Saved#####################\n",
      "Epoch 2\n",
      "100%|██████████| 28123/28123 [5:56:39<00:00,  1.31batch/s, accuracy=0, loss=4.19]     \n",
      "Average Training Loss of Epoch 2: 4.636559 | Acc: 4.19%\n",
      "100%|██████████| 4413/4413 [22:15<00:00,  3.30batch/s, accuracy=0, loss=5.22]\n",
      "Average Validation Loss of Epoch 2: 5.566875 | Acc: 0.50%\n",
      "####################Epoch 2 Model Saved#####################\n",
      "Increment early stopper to 1 because val loss (5.566875257217611) is greater than threshold (5.4576494889872)\n",
      "Epoch 3\n",
      "100%|██████████| 28123/28123 [4:41:08<00:00,  1.67batch/s, accuracy=0, loss=4.99]   \n",
      "Average Training Loss of Epoch 3: 3.936904 | Acc: 10.89%\n",
      "100%|██████████| 4413/4413 [22:40<00:00,  3.24batch/s, accuracy=0, loss=4.62]\n",
      "Average Validation Loss of Epoch 3: 5.661262 | Acc: 0.27%\n",
      "####################Epoch 3 Model Saved#####################\n",
      "Increment early stopper to 2 because val loss (5.6612617891174635) is greater than threshold (5.4576494889872)\n",
      "Epoch 4\n",
      "100%|██████████| 28123/28123 [6:07:06<00:00,  1.28batch/s, accuracy=0, loss=2.96]      \n",
      "Average Training Loss of Epoch 4: 3.288384 | Acc: 20.81%\n",
      "100%|██████████| 4413/4413 [22:44<00:00,  3.23batch/s, accuracy=0, loss=6.6] \n",
      "Average Validation Loss of Epoch 4: 5.735195 | Acc: 0.11%\n",
      "####################Epoch 4 Model Saved#####################\n",
      "Increment early stopper to 3 because val loss (5.735195404975938) is greater than threshold (5.4576494889872)\n",
      "Epoch 5\n",
      "100%|██████████| 28123/28123 [8:54:01<00:00,  1.14s/batch, accuracy=0, loss=3.05]      \n",
      "Average Training Loss of Epoch 5: 2.740239 | Acc: 30.48%\n",
      "100%|██████████| 4413/4413 [22:23<00:00,  3.28batch/s, accuracy=0, loss=6.19]\n",
      "Average Validation Loss of Epoch 5: 5.766478 | Acc: 0.41%\n",
      "####################Epoch 5 Model Saved#####################\n",
      "Increment early stopper to 4 because val loss (5.7664780562733835) is greater than threshold (5.4576494889872)\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28123/28123 [5:04:18<00:00,  1.54batch/s, accuracy=1, loss=1.86]     \n",
      "Average Training Loss of Epoch 6: 2.243220 | Acc: 44.38%\n",
      "100%|██████████| 4413/4413 [22:44<00:00,  3.23batch/s, accuracy=0, loss=6.86]\n",
      "Average Validation Loss of Epoch 6: 5.759455 | Acc: 0.16%\n",
      "####################Epoch 6 Model Saved#####################\n",
      "Increment early stopper to 5 because val loss (5.759455168946865) is greater than threshold (5.4576494889872)\n",
      "Epoch 7\n",
      "100%|██████████| 28123/28123 [4:42:27<00:00,  1.66batch/s, accuracy=0, loss=2.51]   \n",
      "Average Training Loss of Epoch 7: 2.127816 | Acc: 48.69%\n",
      "100%|██████████| 4413/4413 [22:26<00:00,  3.28batch/s, accuracy=0, loss=4.07]\n",
      "Average Validation Loss of Epoch 7: 5.682339 | Acc: 0.11%\n",
      "####################Epoch 7 Model Saved#####################\n",
      "Increment early stopper to 6 because val loss (5.6823389318398325) is greater than threshold (5.4576494889872)\n",
      "Epoch 8\n",
      "100%|██████████| 28123/28123 [6:51:29<00:00,  1.14batch/s, accuracy=0, loss=2.34]       \n",
      "Average Training Loss of Epoch 8: 2.041932 | Acc: 51.49%\n",
      "100%|██████████| 4413/4413 [22:29<00:00,  3.27batch/s, accuracy=0, loss=6.13]\n",
      "Average Validation Loss of Epoch 8: 5.732368 | Acc: 0.09%\n",
      "####################Epoch 8 Model Saved#####################\n",
      "Increment early stopper to 7 because val loss (5.732368027410241) is greater than threshold (5.4576494889872)\n",
      "Epoch 9\n",
      "100%|██████████| 28123/28123 [5:10:33<00:00,  1.51batch/s, accuracy=1, loss=0.764]     \n",
      "Average Training Loss of Epoch 9: 1.963958 | Acc: 54.44%\n",
      "100%|██████████| 4413/4413 [1:47:08<00:00,  1.46s/batch, accuracy=0, loss=5.31]    \n",
      "Average Validation Loss of Epoch 9: 5.802244 | Acc: 0.16%\n",
      "####################Epoch 9 Model Saved#####################\n",
      "Increment early stopper to 8 because val loss (5.80224415123017) is greater than threshold (5.4576494889872)\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28123/28123 [4:41:05<00:00,  1.67batch/s, accuracy=0, loss=2.85]    \n",
      "Average Training Loss of Epoch 10: 1.893262 | Acc: 56.92%\n",
      "100%|██████████| 4413/4413 [22:36<00:00,  3.25batch/s, accuracy=0, loss=5.25]\n",
      "Average Validation Loss of Epoch 10: 5.753560 | Acc: 0.05%\n",
      "####################Epoch 10 Model Saved####################\n",
      "Increment early stopper to 9 because val loss (5.753559931967498) is greater than threshold (5.4576494889872)\n",
      "Epoch 11\n",
      "100%|██████████| 28123/28123 [4:41:54<00:00,  1.66batch/s, accuracy=0, loss=2.43]    \n",
      "Average Training Loss of Epoch 11: 1.882564 | Acc: 57.78%\n",
      "100%|██████████| 4413/4413 [22:44<00:00,  3.24batch/s, accuracy=0, loss=5.03]\n",
      "Average Validation Loss of Epoch 11: 5.780108 | Acc: 0.11%\n",
      "####################Epoch 11 Model Saved####################\n",
      "Increment early stopper to 10 because val loss (5.780107849826895) is greater than threshold (5.4576494889872)\n",
      "Model has overfit, early stopping...\n",
      "#####################Training Finished######################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "r2plus1d_18(\n",
       "  (r2plus1d_18): Sequential(\n",
       "    (0): R2Plus1dStem(\n",
       "      (0): Conv3d(3, 45, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "      (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "      (3): Conv3d(45, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(64, 230, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(128, 230, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(128, 460, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(256, 460, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(256, 921, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(512, 921, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2Plus1D(\n",
       "            (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "            (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "            (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "          )\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=226, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, \n",
    "      train_loader, \n",
    "      val_loader, \n",
    "      no_of_epochs, \n",
    "      logger,\n",
    "      writer,\n",
    "      save_dir=save_dir, \n",
    "      device=device, \n",
    "      patience=10, \n",
    "      optimizer_lr=optimizer_lr, \n",
    "      use_scheduler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd8703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
